{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mental Health Recommender System - Backend Pipeline\n",
    "\n",
    "This notebook consolidates the entire backend logic of the Mental Health Recommender System into a single flow.\n",
    "\n",
    "### Modules Included:\n",
    "1. **Graph Database**: Neo4j Connection Handling\n",
    "2. **Graph Builder**: Populating the graph with synthetic & real data\n",
    "3. **Graph Embedding (ML)**: Training Spectral Embeddings on the graph structure\n",
    "4. **Inference Engine**: Finding similar nodes (Hybrid Recommendation)\n",
    "5. **Recommender API Logic**: The heavy lifting behind the API endpoints\n",
    "\n",
    "### Prerequisites\n",
    "Ensure Neo4j is running locally (`docker-compose up -d`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Configured.\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup & Imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load Environment Variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration (Defaults to localhost if .env is missing)\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"password\")\n",
    "\n",
    "print(\"Environment Configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Connection (`graph/db.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Connection Initialized.\n"
     ]
    }
   ],
   "source": [
    "class Neo4jConnection:\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(Neo4jConnection, cls).__new__(cls)\n",
    "            cls._instance.driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "        return cls._instance\n",
    "\n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "\n",
    "    def query(self, query, parameters=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, parameters)\n",
    "            return [record.data() for record in result]\n",
    "\n",
    "# Global Instance\n",
    "db = Neo4jConnection()\n",
    "print(\"Database Connection Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph Builder (`graph/builder.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_graph():\n",
    "    print(\"Clearing existing graph...\")\n",
    "    db.query(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "def create_constraints():\n",
    "    print(\"Creating constraints...\")\n",
    "    constraints = [\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (u:User) REQUIRE u.id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (c:Country) REQUIRE c.name IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (s:State) REQUIRE s.name IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT IF NOT EXISTS FOR (a:Activity) REQUIRE a.id IS UNIQUE\",\n",
    "        \"CREATE INDEX IF NOT EXISTS FOR (u:User) ON (u.name)\"\n",
    "    ]\n",
    "    for q in constraints:\n",
    "        db.query(q)\n",
    "\n",
    "def load_solutions():\n",
    "    print(\"Loading Synthetic Solutions (Activities/Content)...\")\n",
    "    solutions = [\n",
    "        {'name': 'Mindfulness Meditation', 'type': 'Meditation', 'target': 'Stress'},\n",
    "        {'name': 'Deep Breathing Exercises', 'type': 'Exercise', 'target': 'Stress'},\n",
    "        {'name': 'Stress Management Workshop', 'type': 'Workshop', 'target': 'Stress'},\n",
    "        {'name': 'Emotional Regulation Guidance', 'type': 'Therapy', 'target': 'MoodSwings'},\n",
    "        {'name': 'Journaling for Clarity', 'type': 'Writing', 'target': 'MoodSwings'},\n",
    "        {'name': 'Mood Tracking App', 'type': 'Tool', 'target': 'MoodSwings'},\n",
    "        {'name': 'Group Therapy Session', 'type': 'Social', 'target': 'SocialWeakness'},\n",
    "        {'name': 'Public Speaking Club', 'type': 'Social', 'target': 'SocialWeakness'},\n",
    "        {'name': 'Community Meetup', 'type': 'Social', 'target': 'SocialWeakness'},\n",
    "        {'name': 'Nature Hiking Group', 'type': 'Exercise', 'target': 'Isolation'},\n",
    "        {'name': 'Sunlight Exposure Routine', 'type': 'Routine', 'target': 'Isolation'},\n",
    "        {'name': 'Resilience Training', 'type': 'Training', 'target': 'CopingIssues'},\n",
    "        {'name': 'Cognitive Behavioral Therapy (CBT)', 'type': 'Therapy', 'target': 'CopingIssues'},\n",
    "        {'name': 'Career Counseling', 'type': 'Consultation', 'target': 'WorkBurnout'},\n",
    "        {'name': 'Work-Life Balance Workshop', 'type': 'Workshop', 'target': 'WorkBurnout'},\n",
    "        {'name': 'Maintenance Yoga', 'type': 'Exercise', 'target': 'WellBeing'},\n",
    "        {'name': 'Daily Gratitude Journal', 'type': 'Writing', 'target': 'WellBeing'},\n",
    "    ]\n",
    "\n",
    "    for sol in solutions:\n",
    "        query = \"\"\"\n",
    "        MERGE (a:Activity {name: $name})\n",
    "        SET a.id = $id, a.type = $type\n",
    "        MERGE (s:State {name: $target})\n",
    "        MERGE (a)-[:TREATS]->(s)\n",
    "        \"\"\"\n",
    "        db.query(query, {'name': sol['name'], 'id': str(uuid.uuid4()), 'type': sol['type'], 'target': sol['target']})\n",
    "\n",
    "def load_real_data(limit=100):\n",
    "    # Assuming the CSV is in the parent directory relative to notebook execution context\n",
    "    csv_path = 'Mental Health Dataset.csv'\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Dataset not found at {csv_path}. Skipping real data load.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading users from {csv_path}...\")\n",
    "    df = pd.read_csv(csv_path).head(limit) \n",
    "    \n",
    "    count = 0\n",
    "    for _, row in df.iterrows():\n",
    "        user_id = f\"U{count}\"\n",
    "        country = row.get('Country', 'Unknown')\n",
    "        gender = row.get('Gender', 'Unknown')\n",
    "        \n",
    "        query_user = \"\"\"\n",
    "        MERGE (u:User {id: $uid})\n",
    "        SET u.gender = $gender\n",
    "        MERGE (c:Country {name: $country})\n",
    "        MERGE (u)-[:LIVES_IN]->(c)\n",
    "        \"\"\"\n",
    "        db.query(query_user, {'uid': user_id, 'gender': gender, 'country': country})\n",
    "\n",
    "        # Link to States\n",
    "        if row.get('Growing_Stress') == 'Yes':\n",
    "            db.query(\"MATCH (u:User {id: $uid}) MERGE (s:State {name: 'Stress'}) MERGE (u)-[:EXPERIENCES]->(s)\", {'uid': user_id})\n",
    "        if row.get('Mood_Swings') in ['High', 'Medium']:\n",
    "            db.query(\"MATCH (u:User {id: $uid}) MERGE (s:State {name: 'MoodSwings'}) MERGE (u)-[:EXPERIENCES]->(s)\", {'uid': user_id})\n",
    "        if row.get('Social_Weakness') == 'Yes':\n",
    "            db.query(\"MATCH (u:User {id: $uid}) MERGE (s:State {name: 'SocialWeakness'}) MERGE (u)-[:EXPERIENCES]->(s)\", {'uid': user_id})  \n",
    "        days = row.get('Days_Indoors')\n",
    "        if days and \"More\" in str(days):\n",
    "            db.query(\"MATCH (u:User {id: $uid}) MERGE (s:State {name: 'Isolation'}) MERGE (u)-[:EXPERIENCES]->(s)\", {'uid': user_id})\n",
    "        if row.get('Coping_Struggles') == 'Yes':\n",
    "            db.query(\"MATCH (u:User {id: $uid}) MERGE (s:State {name: 'CopingIssues'}) MERGE (u)-[:EXPERIENCES]->(s)\", {'uid': user_id})\n",
    "        if row.get('Work_Interest') == 'No':\n",
    "            db.query(\"MATCH (u:User {id: $uid}) MERGE (s:State {name: 'WorkBurnout'}) MERGE (u)-[:EXPERIENCES]->(s)\", {'uid': user_id})\n",
    "\n",
    "        count += 1\n",
    "    print(\"Data loading functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Module (`ml/graph_embedding.py` + `inference.py`)\n",
    "Handles Training (Learning Graph Structure) and Inference (Similarity Search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLearner:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.Graph()\n",
    "        self.vectors = {}\n",
    "\n",
    "    def fetch_graph_data(self):\n",
    "        print(\"Fetching data from Neo4j...\")\n",
    "        query = \"\"\"\n",
    "        MATCH (n)-[r]->(m)\n",
    "        RETURN \n",
    "            CASE WHEN n.id IS NOT NULL THEN n.id ELSE n.name END as source,\n",
    "            CASE WHEN m.id IS NOT NULL THEN m.id ELSE m.name END as target,\n",
    "            type(r) as type\n",
    "        \"\"\"\n",
    "        results = db.query(query)\n",
    "        for record in results:\n",
    "            if record['source'] and record['target']:\n",
    "                self.graph.add_edge(record['source'], record['target'])\n",
    "        print(f\"Graph built: {self.graph.number_of_nodes()} nodes.\")\n",
    "\n",
    "    def train_embeddings(self, dimensions=32):\n",
    "        if self.graph.number_of_edges() == 0:\n",
    "            print(\"Graph is empty.\")\n",
    "            return\n",
    "        print(\"Training Spectral Embedding...\")\n",
    "        nodes = list(self.graph.nodes())\n",
    "        adj_matrix = nx.to_numpy_array(self.graph, nodelist=nodes)\n",
    "        embedding = SpectralEmbedding(n_components=dimensions, affinity='precomputed')\n",
    "        node_vectors = embedding.fit_transform(adj_matrix)\n",
    "        self.vectors = {node: vec for node, vec in zip(nodes, node_vectors)}\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "    def save_embeddings(self, filepath=\"graph_embeddings.pkl\"):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.vectors, f)\n",
    "        print(f\"Saved embeddings to {filepath}.\")\n",
    "\n",
    "class NeuralRecommender:\n",
    "    def __init__(self, embedding_path=\"graph_embeddings.pkl\"):\n",
    "        self.vectors = None\n",
    "        self.keys = []\n",
    "        self.matrix = None\n",
    "        self.embedding_path = embedding_path\n",
    "        self.load_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        if os.path.exists(self.embedding_path):\n",
    "            with open(self.embedding_path, 'rb') as f:\n",
    "                self.vectors = pickle.load(f)\n",
    "            self.keys = list(self.vectors.keys())\n",
    "            self.matrix = np.array([self.vectors[k] for k in self.keys])\n",
    "            print(f\"Loaded embeddings for {len(self.vectors)} nodes.\")\n",
    "        else:\n",
    "            print(\"Embedding file not found.\")\n",
    "\n",
    "    def get_activity_details(self, node_id):\n",
    "        query = \"\"\"\n",
    "        MATCH (a:Activity {id: $aid})\n",
    "        RETURN a.id as id, a.name as title, a.type as type, 'Activity' as category\n",
    "        \"\"\"\n",
    "        result = db.query(query, {'aid': node_id})\n",
    "        return result[0] if result else None\n",
    "\n",
    "    def predict(self, user_id, limit=5):\n",
    "        if not self.vectors or user_id not in self.vectors: return []\n",
    "        user_vector = self.vectors[user_id].reshape(1, -1)\n",
    "        scores = cosine_similarity(user_vector, self.matrix)[0]\n",
    "        top_indices = scores.argsort()[::-1]\n",
    "        recommendations = []\n",
    "        for idx in top_indices:\n",
    "            node_id = self.keys[idx]\n",
    "            if node_id == user_id: continue\n",
    "            details = self.get_activity_details(node_id)\n",
    "            if details:\n",
    "                details['score'] = round(float(scores[idx]), 3)\n",
    "                details['reason_category'] = 'AI Match'\n",
    "                recommendations.append(details)\n",
    "            if len(recommendations) >= limit: break\n",
    "        return recommendations\n",
    "\n",
    "    def predict_cold_start(self, distinct_states, limit=5):\n",
    "        if not self.vectors: return []\n",
    "        state_vectors = [self.vectors[s] for s in distinct_states if s in self.vectors]\n",
    "        if not state_vectors: return []\n",
    "        proxy_vector = np.mean(state_vectors, axis=0).reshape(1, -1)\n",
    "        scores = cosine_similarity(proxy_vector, self.matrix)[0]\n",
    "        top_indices = scores.argsort()[::-1]\n",
    "        recommendations = []\n",
    "        for idx in top_indices:\n",
    "            node_id = self.keys[idx]\n",
    "            if node_id in distinct_states: continue\n",
    "            details = self.get_activity_details(node_id)\n",
    "            if details:\n",
    "                details['score'] = round(float(scores[idx]), 3)\n",
    "                details['reason_category'] = 'AI Match'\n",
    "                recommendations.append(details)\n",
    "            if len(recommendations) >= limit: break\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recommendation Engine (`recommender/engine.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self):\n",
    "        self.neural = NeuralRecommender()\n",
    "\n",
    "    def get_recommendations(self, user_id=None, attributes=None, limit=5, strategy='hybrid'):\n",
    "        neural_recs = []\n",
    "        if strategy in ['hybrid', 'neural']:\n",
    "            if user_id:\n",
    "                neural_recs = self.neural.predict(user_id, limit=limit)\n",
    "            elif attributes:\n",
    "                 # Map attributes to states for cold start\n",
    "                target_states = []\n",
    "                if attributes.get('growing_stress') == 'Yes': target_states.append('Stress')\n",
    "                if attributes.get('mood_swings') in ['High', 'Medium']: target_states.append('MoodSwings')\n",
    "                if attributes.get('social_weakness') == 'Yes': target_states.append('SocialWeakness')\n",
    "                if attributes.get('coping_struggles') == 'Yes': target_states.append('CopingIssues')\n",
    "                if attributes.get('work_interest') == 'No': target_states.append('WorkBurnout')\n",
    "                neural_recs = self.neural.predict_cold_start(target_states, limit=limit)\n",
    "\n",
    "            if strategy == 'neural':\n",
    "                return neural_recs\n",
    "\n",
    "        # Graph/Rule Based Logic\n",
    "        graph_recs = []\n",
    "        if user_id:\n",
    "            query = \"\"\"\n",
    "            MATCH (u:User {id: $uid})-[:EXPERIENCES]->(s:State)<-[:TREATS]-(a:Activity)\n",
    "            RETURN a.id as id, a.name as title, a.type as type, s.name as reason_category, 'Activity' as category\n",
    "            LIMIT $limit\n",
    "            \"\"\"\n",
    "            graph_recs = db.query(query, {'uid': user_id, 'limit': limit})\n",
    "        elif attributes:\n",
    "             # Re-map attributes if we didn't do it above (or just reuse logic)\n",
    "            target_states = []\n",
    "            if attributes.get('growing_stress') == 'Yes': target_states.append('Stress')\n",
    "            if attributes.get('mood_swings') in ['High', 'Medium']: target_states.append('MoodSwings')\n",
    "            if attributes.get('social_weakness') == 'Yes': target_states.append('SocialWeakness')\n",
    "            if attributes.get('coping_struggles') == 'Yes': target_states.append('CopingIssues')\n",
    "            if attributes.get('work_interest') == 'No': target_states.append('WorkBurnout')\n",
    "            if not target_states: target_states.append('WellBeing')\n",
    "\n",
    "            query = \"\"\"\n",
    "            MATCH (s:State)<-[:TREATS]-(a:Activity)\n",
    "            WHERE s.name IN $states\n",
    "            RETURN a.id as id, a.name as title, a.type as type, s.name as reason_category, 'Activity' as category\n",
    "            LIMIT $limit\n",
    "            \"\"\"\n",
    "            graph_recs = db.query(query, {'states': target_states, 'limit': limit})\n",
    "\n",
    "        # Hybrid Merge (Interleave)\n",
    "        combined = []\n",
    "        seen = set()\n",
    "        max_len = max(len(graph_recs), len(neural_recs))\n",
    "        for i in range(max_len):\n",
    "            if i < len(graph_recs):\n",
    "                item = graph_recs[i]\n",
    "                if item['id'] not in seen:\n",
    "                    combined.append(item)\n",
    "                    seen.add(item['id'])\n",
    "            if i < len(neural_recs):\n",
    "                item = neural_recs[i]\n",
    "                if item['id'] not in seen:\n",
    "                    combined.append(item)\n",
    "                    seen.add(item['id'])\n",
    "        return combined[:limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Execution & Verification\n",
    "Run the pipeline: Build Graph -> Train Model -> Get Recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing graph...\n",
      "Creating constraints...\n",
      "Loading Synthetic Solutions (Activities/Content)...\n",
      "Loading users from Mental Health Dataset.csv...\n",
      "Data loading functions defined.\n",
      "Fetching data from Neo4j...\n",
      "Graph built: 134 nodes.\n",
      "Training Spectral Embedding...\n",
      "Training complete.\n",
      "Saved embeddings to graph_embeddings.pkl.\n",
      "\n",
      "--- Testing Hybrid Recommender ---\n",
      "Loaded embeddings for 134 nodes.\n",
      "Recommendation for User U0 (Hybrid):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gowth\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:324: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Career Counseling [WorkBurnout]\n",
      " - Maintenance Yoga [AI Match]\n",
      " - Work-Life Balance Workshop [WorkBurnout]\n",
      " - Cognitive Behavioral Therapy (CBT) [AI Match]\n",
      " - Group Therapy Session [SocialWeakness]\n",
      "\n",
      "Cold Start Recommendation (Stress + Mood Swings):\n",
      " - Mindfulness Meditation [Stress]\n",
      " - Deep Breathing Exercises [AI Match]\n",
      " - Emotional Regulation Guidance [AI Match]\n",
      " - Stress Management Workshop [Stress]\n",
      " - Journaling for Clarity [MoodSwings]\n"
     ]
    }
   ],
   "source": [
    "# A. Build Graph (Run once or to reset)\n",
    "clear_graph()\n",
    "create_constraints()\n",
    "load_solutions()\n",
    "load_real_data(limit=100)\n",
    "\n",
    "# B. Train Model\n",
    "learner = GraphLearner()\n",
    "learner.fetch_graph_data()\n",
    "learner.train_embeddings()\n",
    "learner.save_embeddings()\n",
    "\n",
    "# C. Test Recommender\n",
    "print(\"\\n--- Testing Hybrid Recommender ---\")\n",
    "rec = Recommender()\n",
    "\n",
    "# 1. Profile Recommendation (User 0)\n",
    "print(\"Recommendation for User U0 (Hybrid):\")\n",
    "result = rec.get_recommendations(user_id='U0', strategy='hybrid')\n",
    "for r in result:\n",
    "    print(f\" - {r['title']} [{r['reason_category']}]\")\n",
    "\n",
    "# 2. Cold Start Recommendation\n",
    "print(\"\\nCold Start Recommendation (Stress + Mood Swings):\")\n",
    "attrs = {'growing_stress': 'Yes', 'mood_swings': 'High'}\n",
    "result_cold = rec.get_recommendations(attributes=attrs, strategy='hybrid')\n",
    "for r in result_cold:\n",
    "    print(f\" - {r['title']} [{r['reason_category']}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
